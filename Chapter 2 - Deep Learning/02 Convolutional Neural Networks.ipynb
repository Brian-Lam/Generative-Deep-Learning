{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f9e2e7e-a1a4-412b-af03-19cbaf52f0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - accuracy: 0.3886 - loss: 1.8057\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5798 - loss: 1.1898\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6475 - loss: 1.0167\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6758 - loss: 0.9227\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7052 - loss: 0.8445\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-30s\u001b[0m -18998us/step - accuracy: 0.7218 - loss: 0.7934\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7389 - loss: 0.7530  \n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7493 - loss: 0.7136   \n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7648 - loss: 0.6757 \n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.6413  \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7168 - loss: 0.8302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8373697400093079, 0.7171000242233276]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, utils, layers, models, optimizers\n",
    "\n",
    "\n",
    "# Load the CIFAR-10 dataset. This dataset is a collection of 60,000 32x32 color images\n",
    "# in 10 different classes (e.g., airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck).\n",
    "# It's automatically split into training and testing sets.\n",
    "# (x_train, y_train): This contains the training images (x_train) and their corresponding labels (y_train).\n",
    "# (x_test, y_test): This contains the testing images (x_test) and their corresponding labels (y_test).\n",
    "# The images are initially represented as pixel intensity values ranging from 0 to 255.\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Perform Data Pre-processing.\n",
    "#\n",
    "# Normalize the RGB pixel values.\n",
    "# Images are typically represented with pixel values ranging from 0 (black) to 255 (white or full color intensity).\n",
    "# Neural networks generally perform better and train faster when input features are scaled\n",
    "# to a smaller, consistent range, such as 0 to 1.\n",
    "# By dividing by 255.0 (using a float to ensure float division), we transform each pixel value\n",
    "# from its original 0-255 range to a new range between 0.0 and 1.0.\n",
    "# `.astype('float32')`: We also explicitly convert the data type to float32.\n",
    "# This is a common practice in deep learning as models often operate with floating-point numbers\n",
    "# for calculations, and float32 provides a good balance between precision and memory usage.\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Create one-hot encodings for the labels.\n",
    "# Currently, our `y_train` and `y_test` labels are integers (e.g., 0, 1, 2, ..., 9),\n",
    "# where each integer represents a specific class.\n",
    "# For multi-class classification problems with a Softmax output layer (which is typical),\n",
    "# neural networks expect the labels to be in a \"one-hot encoded\" format.\n",
    "#\n",
    "# In one-hot encoding, we have single integer label in a vector where only one element is \"hot\" (1)\n",
    "# and all others are \"cold\" (0). The position of the '1' corresponds to the class.\n",
    "#\n",
    "# Example with NUM_CLASSES = 10:\n",
    "# - If y_label is 0 (e.g., 'airplane'), it becomes [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "# - If y_label is 1 (e.g., 'automobile'), it becomes [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "# - If y_label is 9 (e.g., 'truck'), it becomes [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]\n",
    "#\n",
    "# `utils.to_categorical()`: This Keras utility function performs this conversion for us.\n",
    "# - The first argument is the array of integer labels (`y_train` or `y_test`).\n",
    "# - The second argument, `NUM_CLASSES`, tells the function how long the one-hot vector should be\n",
    "#   (i.e., the total number of possible classes).\n",
    "# Practical benefit: This format allows the network's final Softmax layer to directly output\n",
    "# probabilities for each class, which aligns well with loss functions like `categorical_crossentropy`.\n",
    "y_train = utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "# In this example, we use a convolutional network (with 2D Convolutional Layers) \n",
    "# to power the neural network.\n",
    "#\n",
    "# Our \"Vanilla\" neural network had a key limitation - we had to flatten all the \n",
    "# pixel data into a single long vector at the very beginning (the Flatten layer).\n",
    "# During that time, we lost information about spatial relationships between pixels,\n",
    "# because the network did not know that pixel (1,2) was next to pixel (1,1), or that\n",
    "# a group of pixels formed a shape.\n",
    "# \n",
    "# Then we passed the pixels into a Dense layer, where every neuron in the current layer is connected\n",
    "# to every neuron in the previous layer. Dense layers are great at learning complex,\n",
    "# non-linear relationships between inputs and outputs. However, because they receive a flattened\n",
    "# input, they essentially treat each pixel as an independent feature.\n",
    "#\n",
    "# CNNs (Convolutional Neural Networks) are specifically designed to address the\n",
    "# limitations of traditional dense networks when dealing with structured data like\n",
    "# images. They exploit the spatial relationships within the data.\n",
    "# \n",
    "# Conv2D layers layers apply \"filters\" (also called kernels) that slide across\n",
    "# the input data (e.g., an image). Each filter is a small matrix of learnable weights.\n",
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "# Each Conv2D layer is a core feature extraction layer. \n",
    "#\n",
    "# Take this function call: \n",
    "# layers.Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "# \n",
    "# filters = 32: The layer will learn 32 different filters (also called kernels).\n",
    "# Each filter is designed to detect a specific feature (e.g., a vertical edge, a\n",
    "# diagonal line, a specific color blob) in the input image.\n",
    "# \n",
    "# kernel_size = 3: Each filter will be a 3x3 matrix. This means it will look at a\n",
    "# 3x3 patch of the input image at a time.\n",
    "#\n",
    "# strides = 1: The filter will move one pixel at a time across the input image.\n",
    "#\n",
    "# padding = \"same\": This ensures that the output feature map has the same spatial\n",
    "# dimensions (height and width) as the input feature map\n",
    "x = layers.Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = \"same\")(input_layer)\n",
    "# Then, the Batch Normalization layer normalizes the activations of the previous\n",
    "# layer for each batch during training, to remediate gradient explosion. \n",
    "#\n",
    "#  It significantly helps with training stability, speeds up convergence, and can\n",
    "# act as a mild regularizer, reducing the need for extensive dropout (though dropout\n",
    "# is still used later). It makes the network less sensitive to the initialization of weights.\n",
    "x = layers.BatchNormalization()(x)\n",
    "# Finally, we use a LeakyReLU activation function to introduce non-linearity into the\n",
    "# network.\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Then we do the same, with a stride size of 2 (essentially downsampling the spatial\n",
    "# dimensions of the feature maps)\n",
    "x = layers.Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Then the network learns with 64 different filters, so it's trying to find \n",
    "# more diverse or complex patterns. As we go deeper into a CNN, the filters\n",
    "# tend to learn more abstract and higher-level features by combining the simpler\n",
    "# features detected by earlier layers.\n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Finally, we learn with 64 different filters again, but downsample with a \n",
    "# stride size of 2, so the spatial dimensions are halved. \n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Then we take the multi-dimensional output from the last convolutional block and flatten it into a single 1D vector.\n",
    "# Convolutional layers are excellent at extracting spatial hierarchies of features.\n",
    "# However, for the final classification decision, these extracted features typically\n",
    "# need to be fed into a traditional dense neural network layer, which expects a 1D vector as input.\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "# Dropouts help prevent overfitting. By randomly \"dropping out\" neurons, the network cannot rely\n",
    "# on any single neuron or specific combination of neurons to make predictions. This forces the\n",
    "# network to learn more robust and generalized features, as it needs to be able to make correct\n",
    "# predictions even when some information is missing.\n",
    "x = layers.Dropout(rate = 0.5)(x)\n",
    "\n",
    "output_layer = layers.Dense(10, activation = \"softmax\")(x)\n",
    "\n",
    "model = models.Model(input_layer, output_layer)\n",
    "\n",
    "# Train the model the same way as before\n",
    "opt = optimizers.Adam(learning_rate = 0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size = 32,\n",
    "          epochs = 10,\n",
    "          shuffle = True)\n",
    "\n",
    "model.evaluate(x_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab34a79-15d1-4258-b4c5-b3e06d7fa85b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
